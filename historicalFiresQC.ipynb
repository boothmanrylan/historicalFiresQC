{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "historicalFiresQCMain.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwwyiGlO4hNTJWilfhKoOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/historicalFiresQC/blob/main/historicalFiresQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVhyl04tYrF"
      },
      "source": [
        "# Clone Repository and Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLaVI9MktQD2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab import drive, auth\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import ee\n",
        "import glob\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My\\ Drive/historicalFiresQC\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "# if the directory doesn't exist clone it from github\n",
        "! if [ ! -d ./historicalFiresQC/ ]; then git clone https://github.com/boothmanrylan/historicalFiresQC.git; fi\n",
        "\n",
        "% cd ./historicalFiresQC/\n",
        "! git checkout .\n",
        "! git pull\n",
        "%cd ../\n",
        "\n",
        "! pip install q -r ./historicalFiresQC/requirements.txt\n",
        "\n",
        "from historicalFiresQC import model as Model\n",
        "from historicalFiresQC import data as Data\n",
        "from historicalFiresQC import assessment as Assessment\n",
        "from historicalFiresQC import visualize as Visualize\n",
        "from historicalFiresQC import main as Main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBqcSTNubnF"
      },
      "source": [
        "# Reload Modules\n",
        "\n",
        "This is only necessary to run if changes have been made to the historicalFiresQC modules since you started using the colab notebook. It will pull the changes and reload the modules, allowing the changes to be incorporated without having to restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-Gjg00ua0A"
      },
      "source": [
        "%cd ./historicalFiresQC\n",
        "! git pull\n",
        "%cd ../\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "Model = reload(Model)\n",
        "Data = reload(Data)\n",
        "Assessment = reload(Assessment)\n",
        "Visualize = reload(Visualize)\n",
        "Main = reload(Main)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nIhXssAu7L-"
      },
      "source": [
        "# Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDZcb9epu_rd"
      },
      "source": [
        "params = {\n",
        "    'bucket':                    'gs://boothmanrylan',         # google cloud storage bucket\n",
        "    'data_folder':               'historicalFiresQCInputData', # folder inside bucket containing data\n",
        "    'model_folder':              'historicalFiresQCModels',    # folder inside bucket where models will be saved\n",
        "    'annotation_type':           'bounding_box',               # how annotations were made: level_slice or bounding_box\n",
        "    'output':                    'all',                        # what to predict: all, burn_age, burn\n",
        "    'shape':                     (128, 128),                   # size of 1 input image without bands or batch dimension\n",
        "    'kernel':                    32,                           # edge buffer around each patch\n",
        "    'batch_size':                64,                           # Number of images to consider at once\n",
        "    'stack_image':               False,                        # whether to include the previous image as input to the model\n",
        "    'include_previous_burn_age': False,                        # whether to include the previous burn age as input to the model\n",
        "    'burn_age_function':         'scale',                      # function applied to burn age: scale, log, sigmoid, None\n",
        "    'learning_rate':             1e-4,\n",
        "    'epochs':                    100,\n",
        "    'steps_per_epoch':           100,                          # number of batches run through model in one epoch\n",
        "    'train_model':               False,                        # if false only inference happens \n",
        "    'load_model':                True,                         # if true previously trained model weights will be loaded\n",
        "    'loss_function':             'basic',                      # basic, weigher, or reference_point\n",
        "    'store_predictions':         True,                         # if true model predictions will be stored in model_folder\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAkHcOCgwm7p"
      },
      "source": [
        "# Run Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCtd3ZW-wpp2"
      },
      "source": [
        "output = Main.main(**params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iictFJhHwzy3"
      },
      "source": [
        "# Upload Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ugUmcHKw2vi"
      },
      "source": [
        "import json\n",
        "\n",
        "ee_user = 'users/boothmanrylan'\n",
        "ee_folder = 'historicalFiresQCResults'\n",
        "\n",
        "all_files = !gsutil ls {output['data_folder']}\n",
        "mixers = [x for x in all_files if 'json' in x]\n",
        "mixers.sort()\n",
        "\n",
        "all_files = !gsutil ls {output['model_folder']}\n",
        "tfrecords = [x for x in all_files if '.tfrecord' in x]\n",
        "tfrecords.sort()\n",
        "\n",
        "model_number = output['model_number']\n",
        "\n",
        "for i, (t, m) in enumerate(zip(tfrecords, mixers)):\n",
        "    f = m.replace(output['data_folder'] + '/', '').replace('-mixer.json', '')\n",
        "    asset_id = os.path.join(ee_user, ee_folder, f'{model_number:05d}', f)\n",
        "    !earthengine upload image --asset_id={asset_id} {t} {m}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}