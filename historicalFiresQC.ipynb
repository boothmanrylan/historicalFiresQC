{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "historicalFiresQC.ipynb",
      "provenance": [],
      "mount_file_id": "1R7lPQj3tBjTsyoi1Hm3Dg5NwnXtIgHyY",
      "authorship_tag": "ABX9TyNIuF5caXMY8Tcl21D/eJGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/historicalFiresQC/blob/refdata/historicalFiresQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqTaksZydt5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f856b750-99f3-481d-9d54-0422a5dd9dc0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My\\ Drive/historicalFiresQC\n",
        "! git clone https://github.com/boothmanrylan/historicalFiresQC.git ./\n",
        "! git pull\n",
        "! pip install q -r ./requirements.txt\n",
        "\n",
        "# import modules from historicalFiresQC\n",
        "import model as Model\n",
        "import data as Data\n",
        "import assessment as Assessment\n",
        "import visualize as Visualize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/historicalFiresQC\n",
            "fatal: destination path '.' already exists and is not an empty directory.\n",
            "Already up to date.\n",
            "Collecting git+https://github.com/tensorflow/examples.git (from -r ./requirements.txt (line 1))\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-5xg5lbjd\n",
            "  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-5xg5lbjd\n",
            "Collecting q\n",
            "  Downloading https://files.pythonhosted.org/packages/53/bc/51619d89e0bd855567e7652fa16d06f1ed36a85f108a7fe71f6629bf719d/q-2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from -r ./requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===4138651e621414a8ad4601002490731acbbf2995-->-r ./requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-examples===4138651e621414a8ad4601002490731acbbf2995-->-r ./requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->-r ./requirements.txt (line 2)) (2.7.1)\n",
            "Building wheels for collected packages: tensorflow-examples\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-examples: filename=tensorflow_examples-4138651e621414a8ad4601002490731acbbf2995_-cp36-none-any.whl size=144905 sha256=1eaacedf434ec9825edd0601da689b81eec5b7f61ac37a12df25b3f40ad362f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i6939on9/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d\n",
            "Successfully built tensorflow-examples\n",
            "Installing collected packages: q, tensorflow-examples\n",
            "Successfully installed q-2.6 tensorflow-examples-4138651e621414a8ad4601002490731acbbf2995-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMz5uBq3IT7"
      },
      "source": [
        "# run this cell to include changes made to repo without restarting the runtime\n",
        "!git pull\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "Model = reload(Model)\n",
        "Data = reload(Data)\n",
        "Assessment = reload(Assessment)\n",
        "Visualize = reload(Assessment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ThyYOwggo84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c7d5d4-3fc4-404a-ccdf-90ba0e6ac163"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "PATH = '/content/drive/My Drive/JeffsPicks/'\n",
        "SHAPE = (128, 128, 4)\n",
        "CLASSES = 5\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 10\n",
        "\n",
        "train_patterns = [PATH + 'pick[6-9]*tfrecord.gz', PATH + 'pick1[0-4]*tfrecord.gz']\n",
        "val_pattern = PATH + 'pick[0-1]*tfrecord.gz'\n",
        "test_pattern = PATH + 'pick[2-5]*tfrecord.gz'\n",
        "\n",
        "print('Getting Training Data...')\n",
        "train_dataset = Data.get_dataset(\n",
        "    train_patterns, filters=filter_no_burnt, batch_size=BATCH_SIZE,\n",
        "    shape=SHAPE[:-1]\n",
        ")\n",
        "print('Done Getting Training Data.\\n')\n",
        "\n",
        "print('Getting Validation Data...')\n",
        "val_dataset = Data.get_dataset(\n",
        "    val_pattern, repeat=False, cache=False, shuffle=False,\n",
        "    batch_size=BATCH_SIZE, shape=SHAPE[:-1]\n",
        ")\n",
        "print('Done Getting Validation Data.\\n')\n",
        "\n",
        "print('Getting Test Data...')\n",
        "test_dataset = Data.get_dataset(\n",
        "    test_pattern, repeat=False, cache=False, shuffle=False, batch_size=1,\n",
        "    shape=SHAPE[:-1]\n",
        ")\n",
        "print('Done Getting Test Data.\\n')\n",
        "\n",
        "print('Building Model...')\n",
        "model = Model.build_unet_model(input_shape=SHAPE, classes=CLASSES)\n",
        "print('Done Building Model.\\n')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics=['accuracy']\n",
        "\n",
        "print('Compiling Model...')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "print('Done Compiling Model.\\n')\n",
        "\n",
        "print('Training Model...')\n",
        "model.fit(train_dataset, epochs=EPOCHS, verbose=1, steps_per_epoch=STEPS_PER_EPOCH)\n",
        "print('Done Traing Model.\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Training Data...\n",
            "Done Getting Training Data.\n",
            "\n",
            "Getting Validation Data...\n",
            "Done Getting Validation Data.\n",
            "\n",
            "Getting Test Data...\n",
            "Done Getting Test Data.\n",
            "\n",
            "Building Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py:333: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 4 input channels.\n",
            "  str(input_shape[-1]) + ' input channels.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done Building Model.\n",
            "\n",
            "Compiling Model...\n",
            "Done Compiling Model.\n",
            "\n",
            "Training Model...\n",
            "Epoch 1/10\n",
            " 2/10 [=====>........................] - ETA: 0s - loss: 1.5622 - accuracy: 0.2585WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_end` time: 0.1472s). Check your callbacks.\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 1.4854 - accuracy: 0.3375\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 3s 257ms/step - loss: 1.3306 - accuracy: 0.5283\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 1.1968 - accuracy: 0.6568\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 1.0862 - accuracy: 0.7217\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.9845 - accuracy: 0.7589\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.9142 - accuracy: 0.7708\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.8379 - accuracy: 0.7998\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.7732 - accuracy: 0.8128\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.7300 - accuracy: 0.8214\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.6771 - accuracy: 0.8387\n",
            "Done Traing Model.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}