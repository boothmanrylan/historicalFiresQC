{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/boothmanrylan/historicalFiresQC/blob/main/historicalFiresQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyVhyl04tYrF"
   },
   "source": [
    "# Clone Repository and Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLaVI9MktQD2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from google.colab import drive, auth\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ee\n",
    "import glob\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "%cd /content/drive/My\\ Drive/historicalFiresQC\n",
    "\n",
    "auth.authenticate_user()\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# if expected files don't exist then clone from github\n",
    "! if [ ! -d ./main.py ]; then git clone https://github.com/boothmanrylan/historicalFiresQC.git; fi\n",
    "\n",
    "! git checkout .\n",
    "! git pull\n",
    "\n",
    "! pip install q -r ./requirements.txt\n",
    "\n",
    "import model as Model\n",
    "import data as Data\n",
    "import assessment as Assessment\n",
    "import visualize as Visualize\n",
    "import main as Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbBqcSTNubnF"
   },
   "source": [
    "# Reload Modules\n",
    "\n",
    "This is only necessary to run if changes have been made to the historicalFiresQC modules since you started using the colab notebook. It will pull the changes and reload the modules, allowing the changes to be incorporated without having to restart the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IN-Gjg00ua0A"
   },
   "outputs": [],
   "source": [
    "! git pull\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "Model = reload(Model)\n",
    "Data = reload(Data)\n",
    "Assessment = reload(Assessment)\n",
    "Visualize = reload(Visualize)\n",
    "Main = reload(Main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nIhXssAu7L-"
   },
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDZcb9epu_rd"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bucket':                    'gs://boothmanrylan',         # google cloud storage bucket\n",
    "    'data_folder':               'historicalFiresQCInputData', # folder inside bucket containing data\n",
    "    'model_folder':              'historicalFiresQCModels',    # folder inside bucket where models will be saved\n",
    "    'annotation_type':           'bounding_box',               # how annotations were made: level_slice or bounding_box\n",
    "    'output':                    'all',                        # what to predict: all, burn_age, burn\n",
    "    'shape':                     (128, 128),                   # size of 1 input image without bands or batch dimension\n",
    "    'kernel':                    32,                           # edge buffer around each patch\n",
    "    'batch_size':                64,                           # Number of images to consider at once\n",
    "    'stack_image':               False,                        # whether to include the previous image as input to the model\n",
    "    'include_previous_burn_age': False,                        # whether to include the previous burn age as input to the model\n",
    "    'burn_age_function':         'scale',                      # function applied to burn age: scale, log, sigmoid, None\n",
    "    'learning_rate':             1e-4,\n",
    "    'epochs':                    100,\n",
    "    'steps_per_epoch':           100,                          # number of batches run through model in one epoch\n",
    "    'train_model':               False,                        # if false only inference happens \n",
    "    'load_model':                True,                         # if true previously trained model weights will be loaded\n",
    "    'loss_function':             'basic',                      # basic, weigher, or reference_point\n",
    "    'store_predictions':         True,                         # if true model predictions will be stored in model_folder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAkHcOCgwm7p"
   },
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCtd3ZW-wpp2"
   },
   "outputs": [],
   "source": [
    "output = Main.main(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iictFJhHwzy3"
   },
   "source": [
    "# Upload Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ugUmcHKw2vi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ee_user = 'users/boothmanrylan'\n",
    "ee_folder = 'historicalFiresQCResults'\n",
    "\n",
    "all_files = !gsutil ls {output['data_folder']}\n",
    "mixers = [x for x in all_files if 'json' in x]\n",
    "mixers.sort()\n",
    "\n",
    "all_files = !gsutil ls {output['model_folder']}\n",
    "tfrecords = [x for x in all_files if '.tfrecord' in x]\n",
    "tfrecords.sort()\n",
    "\n",
    "model_number = output['model_number']\n",
    "\n",
    "for i, (t, m) in enumerate(zip(tfrecords, mixers)):\n",
    "    f = m.replace(output['data_folder'] + '/', '').replace('-mixer.json', '')\n",
    "    asset_id = os.path.join(ee_user, ee_folder, f'{model_number:05d}', f)\n",
    "    !earthengine upload image --asset_id={asset_id} {t} {m}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNwwyiGlO4hNTJWilfhKoOt",
   "include_colab_link": true,
   "name": "historicalFiresQCMain.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
