{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of historicalFiresQCMain.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/historicalFiresQC/blob/main/historicalFiresQCMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVhyl04tYrF"
      },
      "source": [
        "# Clone Repository and Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLaVI9MktQD2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab import drive, auth\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import ee\n",
        "import glob\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My\\ Drive/\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "# if expected files don't exist then clone from github\n",
        "! if [ ! -d ./historicalFiresQC ]; then git clone https://github.com/boothmanrylan/historicalFiresQC.git; fi\n",
        "\n",
        "%cd historicalFiresQC\n",
        "\n",
        "! git checkout .\n",
        "! git pull\n",
        "\n",
        "! pip install q -r ./requirements.txt\n",
        "\n",
        "import model as Model\n",
        "import data as Data\n",
        "import assessment as Assessment\n",
        "import visualize as Visualize\n",
        "import main as Main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBqcSTNubnF"
      },
      "source": [
        "# Reload Modules\n",
        "\n",
        "This is only necessary to run if changes have been made to the historicalFiresQC modules since you started using the colab notebook. It will pull the changes and reload the modules, allowing the changes to be incorporated without having to restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-Gjg00ua0A"
      },
      "source": [
        "! git pull\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "Model = reload(Model)\n",
        "Data = reload(Data)\n",
        "Assessment = reload(Assessment)\n",
        "Visualize = reload(Visualize)\n",
        "Main = reload(Main)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nIhXssAu7L-"
      },
      "source": [
        "# Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDZcb9epu_rd"
      },
      "source": [
        "params = {\n",
        "    'bucket':                    'gs://boothmanrylan',         # google cloud storage bucket\n",
        "    'data_folder':               'historicalFiresQCInputData', # folder inside bucket containing data\n",
        "    'model_folder':              'historicalFiresQCModels',    # folder inside bucket where models will be saved\n",
        "    'annotation_type':           'level_slice',               # how annotations were made: level_slice or bounding_box\n",
        "    'output':                    'burn',                        # what to predict: all, burn_age, burn\n",
        "    'shape':                     (128, 128),                   # size of 1 input image without bands or batch dimension\n",
        "    'kernel':                    32,                           # edge buffer around each patch\n",
        "    'batch_size':                64,                           # Number of images to consider at once\n",
        "    'stack_image':               False,                        # whether to include the previous image as input to the model\n",
        "    'include_previous_burn_age': False,                        # whether to include the previous burn age as input to the model\n",
        "    'include_previous_class':    False,\n",
        "    'burn_age_function':         'scale',                      # function applied to burn age: scale, log, sigmoid, None\n",
        "    'learning_rate':             1e-4,\n",
        "    'epochs':                    50,\n",
        "    'steps_per_epoch':           100,                          # number of batches run through model in one epoch\n",
        "    'train_model':               False,                        # if false only inference happens \n",
        "    'load_model':                True,                         # if true previously trained model weights will be loaded\n",
        "    'loss_function':             'basic',                      # basic, weigher, or reference_point\n",
        "    'store_predictions':         False,                         # if true model predictions will be stored in model_folder\n",
        "    'augment_data':              False,\n",
        "    'assess_model':              False\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAkHcOCgwm7p"
      },
      "source": [
        "# Run Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCtd3ZW-wpp2"
      },
      "source": [
        "output = Main.main(**params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNcdZSW92KyW"
      },
      "source": [
        "# Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQn5tOO2UUS"
      },
      "source": [
        "output['assessment'] # display the accuracy assessment table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphQivzFPm6O"
      },
      "source": [
        "if params['output'] == 'burn_age':\n",
        "    max_annot = output['burn_age_function'](3650)\n",
        "elif params['output'] == 'burn':\n",
        "    max_annot = 1\n",
        "else:\n",
        "    max_annot = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8sqEkcbvC-4"
      },
      "source": [
        "Visualize.visualize(\n",
        "    output['train_dataset'],\n",
        "    model=output['model'],\n",
        "    stacked_image=params['stack_image'],\n",
        "    include_prev_burn_age=params['include_previous_burn_age'],\n",
        "    include_prev_class=params['include_previous_class'],\n",
        "    max_annot=max_annot,\n",
        "    max_burn_age=output['burn_age_function'](3650)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9idu6G32AE6"
      },
      "source": [
        "Visualize.visualize(\n",
        "    output['val_dataset'],\n",
        "    model=output['model'],\n",
        "    stacked_image=params['stack_image'],\n",
        "    include_prev_burn_age=params['include_previous_burn_age'],\n",
        "    include_prev_class=params['include_previous_class'],\n",
        "    max_annot=max_annot,\n",
        "    max_burn_age=output['burn_age_function'](3650)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iictFJhHwzy3"
      },
      "source": [
        "# Upload Results\n",
        "Must run main with store_predictions set to True before running thisd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ugUmcHKw2vi"
      },
      "source": [
        "import time\n",
        "import json\n",
        "from IPython.utils import io\n",
        "\n",
        "ee_user = 'users/boothmanrylan'\n",
        "ee_folder = 'historicalFiresQCResults'\n",
        "\n",
        "all_files = !gsutil ls {output['data_folder']}\n",
        "mixers = [x for x in all_files if 'json' in x]\n",
        "mixers.sort()\n",
        "\n",
        "all_files = !gsutil ls {output['model_folder']}\n",
        "tfrecords = [x for x in all_files if '.tfrecord' in x]\n",
        "tfrecords.sort()\n",
        "\n",
        "model_number = output['model_number']\n",
        "\n",
        "image_collection = os.path.join(ee_user, ee_folder, f'{model_number:05d}')\n",
        "\n",
        "!earthengine create collection {image_collection}\n",
        "uploads = {}\n",
        "for i, (t, m) in enumerate(zip(tfrecords, mixers)):\n",
        "    f = m.replace(output['data_folder'] + '/', '').replace('-mixer.json', '')\n",
        "    asset_id = os.path.join(image_collection, f)\n",
        "    print(f'Uploading to {asset_id}')\n",
        "    with io.capture_output() as captured:\n",
        "        !earthengine upload image --asset_id={asset_id} {t} {m}\n",
        "    task_id = captured.stdout.split(' ')[-1].strip()\n",
        "    uploads[asset_id] = [task_id, t, m]\n",
        "\n",
        "successes = []\n",
        "while len(successes) < len(tfrecords):\n",
        "    time.sleep(60)\n",
        "    for asset, task in uploads.items():\n",
        "        if asset in successes: continue\n",
        "        with io.capture_output() as captured:\n",
        "            !earthengine task info {task[0]}\n",
        "        status = captured.stdout.split('State: ')[-1].split(' ')[0].strip()\n",
        "        if status == 'COMPLETED':\n",
        "            print(f'Successfully uploaded {asset}')\n",
        "            successes.append(asset)\n",
        "        elif status == 'FAILED':\n",
        "            if 'Cannot read mixer' in captured.stdout:\n",
        "                print(f'Rerunning upload of {asset}')\n",
        "                with io.capture_output() as captured2:\n",
        "                    !earthengine upload image --asset_id{asset} {task[1]} {task[2]}\n",
        "                new_task_id = captured2.stdout.split(' ')[-1].strip()\n",
        "                uploads[asset] = [new_task_id, task[1], task[2]]\n",
        "            elif 'Cannot overwrite asset' in captured.stdout:\n",
        "                print(f'{asset} already uploaded')\n",
        "                successes.append(asset)\n",
        "            else:\n",
        "                print(f'{asset} failed for unknown reasons; treating as success')\n",
        "                successes.append(asset)\n",
        "        elif status == 'RUNNING':\n",
        "            print(f'{asset} still running')\n",
        "        else:\n",
        "            print(f'{asset} has unknown status skipping')\n",
        "            successes.append(asset)\n",
        "    print(f'Successfully uploaded: {len(successes)} files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdgWSvhrG0bZ"
      },
      "source": [
        "task_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88UVuDqJ-Tnm"
      },
      "source": [
        "!earthengine task info OBNMKAS5ACYUNZQDF6DPYS3Y"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}